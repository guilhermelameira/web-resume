{"version":3,"sources":["AppInput.tsx","components/Header.tsx","components/RichText.tsx","components/SectionText.tsx","components/Entry.tsx","components/Section.tsx","components/Body.tsx","AppOutput.tsx","tokenizer/Tokens.ts","tokenizer/Tokenizer.ts","parser/AbstractParser.ts","parser/ParserError.ts","parser/VarDecParser.ts","parser/DataParser.ts","parser/PlaintextParser.ts","parser/HeaderParser.ts","parser/TextParser.ts","parser/RichTextParser.ts","parser/SummaryParser.ts","parser/EntryParser.ts","parser/SectionParser.ts","parser/BodyParser.ts","parser/ProgramParser.ts","parser/ResumeParser.ts","App.tsx","serviceWorker.ts","index.tsx"],"names":["AppInput","props","id","value","inputValue","onChange","e","handleInputValueChange","target","Header","ast","name","links","className","map","link","index","key","RichText","Fragment","piece","decorator","trim","iconClassName","replace","split","some","num","indexOf","match","numIndex","length","iconName","substring","iconSize","SectionText","is_bullet","Entry","title","subtitle","summary","s","Section","entries","entry","Body","section","AppOutput","parsed","error","toString","header","body","Tokens","HEADER_BODY_DIV","EMPHASIS_DECORATOR_START","EMPHASIS_DECORATOR_END","NEW_LINE","USER_NAME","SECTION_TITLE_KEY","ENTRY_TITLE_KEY","ENTRY_SUBTITLE_KEY","TOKEN_DECORATOR_START","TOKEN_DECORATOR_END","BULLET_KEY","LINE_BREAK","ICON_START","ICON_END","literals","DATA_START","VAR_KEYWORD","VAR_DEC_START","VAR_DEC_END","Tokenizer","programString","program","tokens","currentIdx","lineNumber","this","tokenize","charAt","literal","regex","RegExp","escapeRegex","enhanced","join","console","log","peek","token","Error","str","AbstractParser","ParserError","expected","actual","VarDecParser","context","getCurrentLine","getNext","test","t","DataParser","hasNext","varMap","Map","varDec","parse","set","PlaintextParser","delimiter","delimiterList","text","includes","HeaderParser","headerStart","nameParsed","push","parseLink","linkParsed","TextParser","initialText","RichTextParser","nextToken","SummaryParser","sectionText","EntryParser","entryEndArray","SectionParser","sectionTitle","sectionTitleKey","BodyParser","ProgramParser","divHB","ResumeParser","subProgram","forEach","varName","dataStartIdx","p","App","state","parsedValue","parsedError","runParser","parsedResume","setState","a","render","Component","Boolean","window","location","hostname","ReactDOM","document","getElementById","navigator","serviceWorker","ready","then","registration","unregister"],"mappings":"iVAceA,EATV,SAAAC,GAAK,OACR,yBAAKC,GAAG,SACN,8BACEC,MAAOF,EAAMG,WACbC,SAAU,SAACC,GAAD,OAAOL,EAAMM,uBAAuBD,EAAEE,OAAOL,YCY9CM,EAhBV,SAAC,GAAD,QACHC,IACEC,EAFC,EAEDA,KACAC,EAHC,EAGDA,MAHC,OAMH,4BAAQC,UAAU,UAChB,wBAAIA,UAAU,QAAQF,EAAKR,OAC3B,uBAAGU,UAAU,WACVD,EAAME,KAAI,SAACC,EAAMC,GAAP,OACT,uBAAGC,IAAKD,GAAQD,EAAKZ,aC0Bde,EApCV,SAAC,GAAD,IAAGR,EAAH,EAAGA,IAAH,OACH,kBAAC,IAAMS,SAAP,KACGT,EAAII,KAAI,SAACM,EAAOJ,GACf,GAAwB,aAApBI,EAAMC,UACR,OAAO,uBAAGJ,IAAKD,GAAQI,EAAMjB,OACxB,GAAwB,UAApBiB,EAAMC,UACf,OAAO,8BAAM,4BAAQJ,IAAKD,GAAQI,EAAMjB,MAAMmB,QAAvC,QACF,GAAwB,SAApBF,EAAMC,UAAsB,CAErC,IAAIE,EAAgB,WACdpB,EAAQiB,EAAMjB,MAAMqB,QAAQ,MAAM,IAIxC,GAHe,aACZC,MAAM,IACNC,MAAK,SAAAC,GAAG,OAAIxB,EAAMyB,QAAQD,IAAQ,KACzB,CACV,IAAME,EAAQ1B,EAAM0B,MAAM,OAC1B,GAAIA,EAAO,CACT,IAAMC,EAAWD,EAAMb,OAASb,EAAM4B,OAChCC,EAAW7B,EAAM8B,UAAU,EAAGH,EAAW,GACzCI,EAAW/B,EAAM8B,UAAUH,EAAU3B,EAAM4B,QACjDR,GAAa,kBAAeS,EAAf,oBAAmCE,SAGlDX,GAAa,kBAAepB,GAE9B,OAAO,8BAAM,uBAAGc,IAAKD,EAAOH,UAAWU,IAAhC,QAET,OACE,kBAAC,IAAMJ,SAAP,CAAgBF,IAAKD,GAClBI,EAAMjB,YCRFgC,EApBV,SAAC,GAAD,QACHzB,IACEP,EAFC,EAEDA,MACAiC,EAHC,EAGDA,UAHC,OAMH,kBAAC,IAAMjB,SAAP,KACGiB,GACD,wBAAIvB,UAAU,UACZ,kBAAC,EAAD,CAAUH,IAAKP,MAGfiC,GACF,2BACE,kBAAC,EAAD,CAAU1B,IAAKP,OCWNkC,EAxBV,SAAC,GAMC,IAAD,IALJ3B,IACE4B,EAIE,EAJFA,MACAC,EAGE,EAHFA,SACAC,EAEE,EAFFA,QAGF,OACE,wBAAI3B,UAAU,SACVyB,GAASA,EAAMP,OAAW,wBAAIlB,UAAU,SACxC,kBAAC,EAAD,CAAUH,IAAK4B,KACT,KACNC,GAAYA,EAASR,OACrB,wBAAIlB,UAAU,SACZ,kBAAC,EAAD,CAAUH,IAAK6B,KAEf,KACHC,EAAQ1B,KAAI,SAAC2B,EAAGzB,GAAJ,OACX,kBAAC,EAAD,CAAaC,IAAKD,EAAON,IAAK+B,SCAvBC,EAlBV,SAAC,GAKC,IAAD,IAJJhC,IACE4B,EAGE,EAHFA,MACAK,EAEE,EAFFA,QAGF,OACE,yBAAK9B,UAAU,WACb,wBAAIA,UAAU,SACZ,kBAAC,EAAD,CAAUH,IAAK4B,KAEhBK,EAAQ7B,KAAI,SAAC8B,EAAO5B,GAAR,OACX,kBAAC,EAAD,CAAOC,IAAKD,EAAON,IAAKkC,SCHjBC,EAVV,SAAC,GAAD,IACHnC,EADG,EACHA,IADG,OAGH,0BAAMG,UAAU,QACbH,EAAII,KAAI,SAACgC,EAAS9B,GAAV,OACP,kBAAC,EAAD,CAASC,IAAKD,EAAON,IAAKoC,SCcjBC,EAjBV,SAAC,GAAD,IACHC,EADG,EACHA,OACAC,EAFG,EAEHA,MAFG,OAIH,yBAAK/C,GAAG,SAASW,UAAU,UACxBoC,GACC,6BAAMA,EAAMC,aAEZD,GAASD,GACL,yBAAKnC,UAAU,iBACb,kBAAC,EAAD,CAAQH,IAAKsC,EAAOG,SACnBH,EAAOI,MAAQ,kBAAC,EAAD,CAAM1C,IAAKsC,EAAOI,U,2BClBzBC,E,kCAAAA,EACHC,gBAAkB,KADfD,EAEHE,yBAA2B,KAFxBF,EAGHG,uBAAyB,KAHtBH,EAIHI,SAAW,WAJRJ,EAKHK,UAAY,IALTL,EAMHM,kBAAoB,IANjBN,EAOHO,gBAAkB,KAPfP,EAQHQ,mBAAqB,MARlBR,EASHS,sBAAwB,KATrBT,EAUHU,oBAAsB,KAVnBV,EAWHW,WAAa,IAXVX,EAYHY,WAAa,KAZVZ,EAaHa,WAAa,KAbVb,EAcHc,SAAW,KAdRd,EAeHe,SAAW,CACrBf,EAAOG,uBACPH,EAAOE,yBACPF,EAAOU,oBACPV,EAAOS,sBACPT,EAAOW,WACPX,EAAOY,WACPZ,EAAOa,WACPb,EAAOc,UAvBMd,EAyBHgB,WAAa,QAzBVhB,EA0BHiB,YAAc,MA1BXjB,EA2BHkB,cAAgB,IA3BblB,EA4BHmB,YAAc,I,ICxBXC,E,WAMjB,WAAYC,GAAwB,yBAL5BC,aAK2B,OAJ3BC,YAI2B,OAH3BC,gBAG2B,OAF3BC,gBAE2B,EAC/BC,KAAKJ,QAAUD,EACfK,KAAKH,OAAS,GACdG,KAAKF,WAAa,EAClBE,KAAKD,WAAa,EAClBC,KAAKC,W,uDAILD,KAAKJ,QAAUI,KAAKJ,QAAQM,OAAO,GAAK,IAAMF,KAAKJ,QAAQ1C,UAAU,GADhD,2BAIrB,IAAI,IAAJ,IAAmBoB,EAAOe,SAA1B,+CAAmC,CAAC,IAA5Bc,EAA2B,QAC3BC,EAAQ,IAAIC,OAAOL,KAAKM,YAAYH,GAAS,KACjDH,KAAKJ,QAAUI,KAAKJ,QAAQnD,QAAQ2D,EAAO,IAAID,EAAQ,MANtC,kFAQrBH,KAAKJ,QAAUI,KAAKJ,QAAQnD,QAAQ,OAAQ,MAC5C,IAAI8D,EAAWP,KAAKJ,QAAQlD,MAAM,MAAM8D,KAAK,cAE7CR,KAAKH,OAASU,EAASzD,MAAM,QAC7B2D,QAAQC,IAAI,UAAWV,KAAKH,U,gCAK5B,GAAmB,MAAfG,KAAKW,OAAgB,CACrB,IAAIC,EAAQZ,KAAKH,OAAOG,KAAKF,YAK7B,OAJAE,KAAKF,aACDc,IAAUtC,EAAOI,UACjBsB,KAAKD,aAEFa,EAEX,MAAM,IAAIC,MAAM,+B,6BAKhB,OAAIb,KAAKF,WAAaE,KAAKH,OAAO7C,OACvBgD,KAAKH,OAAOG,KAAKF,YAErB,O,gCAKP,OAAuB,OAAhBE,KAAKW,S,uCAIZ,OAAOX,KAAKD,a,kCAIIe,GAChB,OAAOA,EAAIrE,QAAQ,sCAAuC,Y,KChE5CsE,EAAtB,kC,QCFqBC,E,YACjB,WAAYC,EAAkBC,EAAgBnB,GAAqB,wFAC7CkB,EAD4C,oBACxBC,EADwB,qBACLnB,K,uCAFxBc,QCM5BM,EAAb,8KACUC,GACF,GAAIA,EAAQT,SAAWrC,EAAOiB,YAC1B,MAAM,IAAIyB,EAAY1C,EAAOiB,YAAa6B,EAAQT,OAASS,EAAQC,kBAEvED,EAAQE,UACR,IAAM1F,EAAOwF,EAAQE,UAErB,IADajB,OAAO,mBACRkB,KAAK3F,GACb,MAAM,IAAIoF,EAAY,gBAAiBpF,EAAMwF,EAAQC,kBAEzD,GAAID,EAAQT,SAAWrC,EAAOkB,cAC1B,MAAM,IAAIwB,EAAY1C,EAAOkB,cAAe4B,EAAQT,OAASS,EAAQC,kBAEzED,EAAQE,UAER,IADA,IAAIR,EAAM,GACHM,EAAQT,SAAWrC,EAAOmB,aAAa,CAC1C,IAAM+B,EAAIJ,EAAQE,UACdE,IAAMlD,EAAOI,SACboC,GAAO,KAEPA,GAAG,UAAOU,EAAP,KAIX,OADAJ,EAAQE,UACD,CACH1F,OACAR,MAAO0F,OA3BnB,GAAkCC,GCArBU,EAAb,8KACUL,GACF,KAAOA,EAAQM,WAAaN,EAAQT,SAAWrC,EAAOgB,YAClD8B,EAAQE,UAERF,EAAQM,WACRN,EAAQE,UAGZ,IADA,IAAIK,EAAiB,IAAIC,IAClBR,EAAQM,WAAW,CACtB,KAAON,EAAQT,SAAWrC,EAAOI,UAC7B0C,EAAQE,UAEZ,GAAIF,EAAQT,SAAWrC,EAAOiB,YAAa,CACvC,IAAIsC,GAAS,IAAIV,GAAeW,MAAMV,GACtCO,EAAOI,IAAIF,EAAOjG,KAAMiG,GAE5B,KAAOT,EAAQT,SAAWrC,EAAOI,UAC7B0C,EAAQE,UAGhB,OAAOK,MArBf,GAAgCZ,GCAXiB,E,YAOjB,WAAYC,GAAoB,IAAD,8BAC3B,+CAPaA,eAMc,IALdC,cAAgB,CAAC5D,EAAOS,sBACrCT,EAAOE,yBACPF,EAAOa,WACPb,EAAOI,UAIP,EAAKuD,UAAYA,EAFU,E,mEAKzBb,GACF,IAAIe,EAAO,GACX,OAAQnC,KAAKiC,WACT,IAAK,GAED,IADA,IAAItB,EAAOS,EAAQT,OACH,OAATA,IACCX,KAAKkC,cAAcE,SAASzB,IAGhCwB,GAAQf,EAAQE,UAAY,IAC5BX,EAAOS,EAAQT,OAEnB,MAEJ,QACI,KAAOS,EAAQT,SAAWX,KAAKiC,WAC3BE,GAAQf,EAAQE,UAAY,IAKxC,MAAO,CACHlG,MAAO+G,O,GAlC0BpB,GCExBsB,E,8KACXjB,GAEF,IAAIkB,EAAclB,EAAQE,UAC1B,GAAIgB,IAAgBhE,EAAOK,UACvB,MAAM,IAAIqC,EAAY1C,EAAOK,UAAW2D,EAAalB,EAAQC,kBAEjE,IAAIkB,EAAa,IAAIP,EAAgB1D,EAAOI,UAAUoD,MAAMV,GAC5DA,EAAQE,UAIR,IADA,IAAIzF,EAAQ,GACLuF,EAAQM,WAAaN,EAAQT,SAAWrC,EAAOC,iBAClD1C,EAAM2G,KAAKxC,KAAKyC,UAAUrB,IAG9B,MAAO,CACHxF,KAAM2G,EACN1G,MAAOA,K,gCAILuF,GACN,IAAIsB,EAAa,IAAIV,EAAgB1D,EAAOI,UAAUoD,MAAMV,GAE5D,OADAA,EAAQE,UACDoB,M,GAzB2B3B,GCF7B4B,EAAb,8KACUvB,GAEF,IAAIe,EAAO,GAEPS,EAAc,GAGlB,OAAQxB,EAAQT,QACZ,KAAKrC,EAAOE,yBAER4C,EAAQE,UAERsB,EADkB,IAAIZ,EAAgB1D,EAAOG,wBACfqD,MAAMV,GACpCe,EAAK/G,MAAQwH,EAAYxH,MACzB+G,EAAK7F,UAAY,WACjB8E,EAAQE,UACR,MACJ,KAAKhD,EAAOS,sBAERqC,EAAQE,UAERsB,EADkB,IAAIZ,EAAgB1D,EAAOU,qBACf8C,MAAMV,GACpCe,EAAK/G,MAAQwH,EAAYxH,MACzB+G,EAAK7F,UAAY,QACjB8E,EAAQE,UACR,MACJ,KAAKhD,EAAOY,WAERkC,EAAQE,UACJF,EAAQT,SAAWrC,EAAOI,UAC1B0C,EAAQE,UAEZa,EAAK/G,MAAQ,GACb+G,EAAK7F,UAAY,QACjB,MACJ,KAAKgC,EAAOa,WAERiC,EAAQE,UAERsB,EADkB,IAAIZ,EAAgB1D,EAAOc,UACf0C,MAAMV,GACpCe,EAAK/G,MAAQwH,EAAYxH,MACzB+G,EAAK7F,UAAY,OACjB8E,EAAQE,UACR,MACJ,QAGIsB,EADkB,IAAIZ,EAAgB,IACRF,MAAMV,GACpCe,EAAK/G,MAAQwH,EAAYxH,MACzB+G,EAAK7F,UAAY,MAIzB,OAAO6F,MAtDf,GAAgCpB,GCAnB8B,EAAb,8KACUzB,GAGF,IAFA,IAAIhG,EAAQ,GACR0H,EAAY1B,EAAQT,OACH,OAAdmC,GAAoB,CACvB,IAAMtB,GAAI,IAAImB,GAAab,MAAMV,GAKjC,GAJAhG,EAAMoH,KAAKhB,IACXsB,EAAY1B,EAAQT,UAGFrC,EAAOI,SAAU,CAC/B0C,EAAQE,UACR,OAGR,OAAOlG,MAff,GAAoC2F,GCAvBgC,EAAb,8KACU3B,GACF,IAAI4B,EAAc,GAEdF,EAAY1B,EAAQT,OAaxB,OAZImC,IAAcxE,EAAOW,YACrB+D,EAAY3F,WAAY,EACxB+D,EAAQE,UACRwB,EAAY1B,EAAQT,QAEpBqC,EAAY3F,WAAY,EAG5B2F,EAAY5H,MAAQ,GACF,OAAd0H,IACAE,EAAY5H,OAAQ,IAAIyH,GAAiBf,MAAMV,IAE5C4B,MAjBf,GAAmCjC,GCEtBkC,EAAb,2MACYC,cAAgB,CAAC5E,EAAOM,kBAAmBN,EAAOQ,mBAAoBR,EAAOO,iBADzF,qEAGUuC,GACF,IAAI7D,EAAkB,GAClBC,EAAqB,GAErB4D,EAAQT,SAAWrC,EAAOO,kBAC1BuC,EAAQE,UACR/D,GAAQ,IAAIsF,GAAiBf,MAAMV,IAGnCA,EAAQT,SAAWrC,EAAOQ,qBAC1BsC,EAAQE,UACR9D,GAAW,IAAIqF,GAAiBf,MAAMV,IAM1C,IAHA,IAAI3D,EAAU,GACVkD,EAAOS,EAAQT,OAEH,OAATA,IAAmBX,KAAKkD,cAAcd,SAASzB,IAClDlD,EAAQ+E,MAAK,IAAIO,GAAgBjB,MAAMV,IACvCT,EAAOS,EAAQT,OAGnB,MAAO,CACHpD,MAAOA,EACPC,SAAUA,EACVC,QAASA,OA5BrB,GAAiCsD,GCEZoC,E,8KACX/B,GAEF,IACIgC,EADAC,EAAkBjC,EAAQE,UAE9B,GAAI+B,IAAoB/E,EAAOM,kBAG3B,MAAM,IAAIoC,EAAY1C,EAAOM,kBAAmByE,EAAiBjC,EAAQC,kBAFzE+B,GAAe,IAAIP,GAAiBf,MAAMV,GAM9C,IADA,IAAIxD,EAAU,GACPwD,EAAQM,WAAaN,EAAQT,SAAWrC,EAAOM,mBAAmB,CACrE,IAAIf,GAAQ,IAAIoF,GAAcnB,MAAMV,GACpCxD,EAAQ4E,KAAK3E,GAGjB,MAAO,CACHN,MAAO6F,EACPxF,QAASA,O,GAnBsBmD,GCJtBuC,E,8KACXlC,GACF,IAAI/C,EAAO,GAEX,EAAG,CACC,IAAIN,EAAU,IAAIoF,EAClB9E,EAAKmE,KAAKzE,EAAQ+D,MAAMV,UACnBA,EAAQM,WACjB,OAAOrD,M,GARyB0C,GCE3BwC,EAAb,8KACiBnC,GACT,IAAIhD,EACAC,EAIJ,GADAD,GADmB,IAAIiE,GACDP,MAAMV,GACxBA,EAAQM,UAAW,CACnB,IAAI8B,EAAQpC,EAAQE,UACpB,GAAIkC,IAAUlF,EAAOC,gBACjB,MAAM,IAAIyC,EAAY1C,EAAOC,gBAAiBiF,EAAOpC,EAAQC,kBAEjED,EAAQE,UAGRjD,GADiB,IAAIiF,GACHxB,MAAMV,GAE5B,MAAO,CACHhD,SACAC,YAnBZ,GAAmC0C,GCDtB0C,EAAb,mGACiB7D,GACT,IAAI4B,EAAI,IAAI9B,EAAUE,GAClB+B,GAAS,IAAIF,GAAaK,MAAMN,GAChCkC,EAAa9D,EACjB+B,EAAOgC,SAAQ,SAACC,GACZF,EAAaA,EAAWjH,QAAX,WAAuBmH,EAAQhI,MAAQgI,EAAQxI,UAEhE,IAAMyI,EAAeH,EAAW7G,QAAQyB,EAAOgB,aACzB,IAAlBuE,IACAH,EAAaA,EAAWxG,UAAU,EAAG2G,IAEzCpD,QAAQC,IAAIgD,GACZ,IAAII,EAAI,IAAIP,EAGZ,OADA/B,EAAI,IAAI9B,EAAUgE,GACXI,EAAEhC,MAAMN,OAhBvB,KC+CeuC,E,2MA7CbC,MAAQ,CACN3I,WAAY,GACZ4I,YAAa,KACbC,YAAa,M,EAGfC,UAAY,WACV,IAAIC,EAAe,KACnB,IACEA,EAAeX,EAAa3B,MAAM,EAAKkC,MAAM3I,YAC7C,EAAKgJ,SAAS,CACZJ,YAAaG,EACbF,YAAa,OAEf,MAAO3I,GACP,EAAK8I,SAAS,CAACH,YAAa3I,M,EAIhCC,uB,uCAAyB,WAAOJ,GAAP,SAAAkJ,EAAA,sEACjB,EAAKD,SAAS,CAAChJ,WAAYD,IADV,OAEvB,EAAK+I,YAFkB,2C,wDAKzBI,OAAS,WACP,OACE,yBAAKpJ,GAAG,QAIN,yBAAKA,GAAG,WACN,kBAAC,EAAD,CACEE,WAAY,EAAK2I,MAAM3I,WACvBG,uBAAwB,EAAKA,yBAE/B,kBAAC,EAAD,CACEyC,OAAQ,EAAK+F,MAAMC,YACnB/F,MAAO,EAAK8F,MAAME,iB,6BAtCZM,aCIEC,QACW,cAA7BC,OAAOC,SAASC,UAEe,UAA7BF,OAAOC,SAASC,UAEhBF,OAAOC,SAASC,SAAS9H,MACvB,2DCZN+H,IAASN,OAAO,kBAAC,EAAD,MAASO,SAASC,eAAe,SDmI3C,kBAAmBC,WACrBA,UAAUC,cAAcC,MAAMC,MAAK,SAAAC,GACjCA,EAAaC,kB","file":"static/js/main.069babd1.chunk.js","sourcesContent":["import React from 'react';\n\nconst AppInput: React.FC<{\n  inputValue: string;\n  handleInputValueChange(value: string): void;\n}> = props => (\n  <div id=\"input\">\n    <textarea\n      value={props.inputValue}\n      onChange={(e) => props.handleInputValueChange(e.target.value)}\n    />\n  </div>\n);\n\nexport default AppInput;\n","import React from 'react';\nimport {Header as TypeHeader} from '../types/Header';\n\nconst Header: React.FC<{\n  ast: TypeHeader\n}> = ({\n  ast: {\n    name,\n    links\n  }\n}) => (\n  <header className=\"header\">\n    <h1 className=\"name\">{name.value}</h1>\n    <p className=\"contact\">\n      {links.map((link, index) => (\n        <a key={index}>{link.value}</a>\n      ))}\n    </p>\n  </header>\n);\n\nexport default Header;\n","import React from 'react';\nimport {RichText as TypeRichText} from '../types/Text';\n\nconst RichText: React.FC<{\n  ast: TypeRichText\n}> = ({ ast }) => (\n  <React.Fragment>\n    {ast.map((piece, index) => {\n      if (piece.decorator === 'EMPHASIS') {\n        return <b key={index}>{piece.value}</b>;\n      } else if (piece.decorator === 'TOKEN') {\n        return <span><strong key={index}>{piece.value.trim()}</strong>&nbsp;</span>;\n      } else if (piece.decorator === 'ICON') {\n        // TODO icons need a better abstract syntax\n        let iconClassName = 'icofont ';\n        const value = piece.value.replace(/\\s/g,'');\n        const hasNum = '0123456789'\n          .split('')\n          .some(num => value.indexOf(num) >= 0);\n        if (hasNum) {\n          const match = value.match(/\\d+/);\n          if (match) {\n            const numIndex = match.index || value.length;\n            const iconName = value.substring(0, numIndex - 1);\n            const iconSize = value.substring(numIndex, value.length);\n            iconClassName += `icofont-${iconName} icofont-${iconSize}`;\n          }\n        } else {\n          iconClassName += `icofont-${value}`;\n        }\n        return <span><i key={index} className={iconClassName} />&nbsp;</span>;\n      }\n      return (\n        <React.Fragment key={index}>\n          {piece.value}\n        </React.Fragment>\n      );\n    })}\n  </React.Fragment>\n);\n\nexport default RichText;\n","import React from 'react';\nimport {SectionText as TypeSectionText} from '../types/Text';\nimport RichText from './RichText';\n\nconst SectionText: React.FC<{\n  ast: TypeSectionText\n}> = ({\n  ast: {\n    value,\n    is_bullet\n  }\n}) => (\n  <React.Fragment>\n    {is_bullet && (\n    <li className=\"bullet\">\n      <RichText ast={value} />\n    </li>\n    )}\n    {!is_bullet && (\n    <p>\n      <RichText ast={value} />\n    </p>\n    )}\n  </React.Fragment>\n);\n\nexport default SectionText;\n","import React from 'react';\nimport {Entry as TypeEntry} from '../types/Section';\nimport RichText from './RichText';\nimport SectionText from './SectionText';\n\nconst Entry: React.FC<{\n  ast: TypeEntry\n}> = ({\n  ast: {\n    title,\n    subtitle,\n    summary\n  }\n}) => {\n  return (\n    <ul className=\"entry\">\n      {(title && title.length) ? (<h3 className=\"title\">\n        <RichText ast={title} />\n      </h3>): null}\n      {(subtitle && subtitle.length) ? (\n        <h4 className=\"title\">\n          <RichText ast={subtitle} />\n        </h4>\n      ) : null}\n      {summary.map((s, index) => (\n        <SectionText key={index} ast={s} />\n      ))}\n    </ul>\n  );\n};\n\nexport default Entry;\n","import React from 'react';\nimport {Section as TypeSection} from '../types/Section';\nimport Entry from './Entry';\nimport RichText from './RichText';\n\nconst Section: React.FC<{\n  ast: TypeSection\n}> = ({\n  ast: {\n    title,\n    entries\n  }\n}) => {\n  return (\n    <div className=\"section\">\n      <h2 className=\"title\">\n        <RichText ast={title} />\n      </h2>\n      {entries.map((entry, index) => (\n        <Entry key={index} ast={entry} />\n      ))}\n    </div>\n  );\n};\n\nexport default Section;\n","import React from 'react';\nimport {Body as TypeBody} from '../types/Body';\nimport Section from './Section';\n\nconst Body: React.FC<{\n  ast: TypeBody\n}> = ({\n  ast\n}) => (\n  <main className=\"body\">\n    {ast.map((section, index) => (\n      <Section key={index} ast={section} />\n    ))}\n  </main>\n);\n\nexport default Body;\n","import React from 'react';\nimport {Program as TypeProgram} from './types/Program';\nimport Header from './components/Header';\nimport Body from './components/Body';\n\nconst AppOutput: React.FC<{\n  parsed: TypeProgram | null,\n  error: any\n}> = ({\n  parsed,\n  error\n}) => (\n  <div id=\"output\" className=\"canvas\">\n    {error && (\n      <div>{error.toString()}</div>\n    )}\n    {!error && parsed && (\n          <div className=\"resume letter\">\n            <Header ast={parsed.header} />\n            {parsed.body && <Body ast={parsed.body} />}\n          </div>\n    )}\n  </div>\n);\n\nexport default AppOutput;\n","// List of Tokens (in regex) in our language\nexport default class Tokens {\n    public static HEADER_BODY_DIV = \"==\"\n    public static EMPHASIS_DECORATOR_START = \"**\"\n    public static EMPHASIS_DECORATOR_END = \"**\"\n    public static NEW_LINE = \"NEW_LINE\"\n    public static USER_NAME = \"@\"\n    public static SECTION_TITLE_KEY = \"#\"\n    public static ENTRY_TITLE_KEY = \"##\"\n    public static ENTRY_SUBTITLE_KEY = \"###\"\n    public static TOKEN_DECORATOR_START = \"((\"\n    public static TOKEN_DECORATOR_END = \"))\"\n    public static BULLET_KEY = \"-\"\n    public static LINE_BREAK = \"++\"\n    public static ICON_START = \"[[\"\n    public static ICON_END = \"]]\"\n    public static literals = [\n        Tokens.EMPHASIS_DECORATOR_END,\n        Tokens.EMPHASIS_DECORATOR_START,\n        Tokens.TOKEN_DECORATOR_END,\n        Tokens.TOKEN_DECORATOR_START,\n        Tokens.BULLET_KEY,\n        Tokens.LINE_BREAK,\n        Tokens.ICON_START,\n        Tokens.ICON_END\n    ]\n    public static DATA_START = \"DATA:\"\n    public static VAR_KEYWORD = \"var\"\n    public static VAR_DEC_START = \"{\"\n    public static VAR_DEC_END = \"}\"\n}\n\n","// Tokenizer is a read-only stack-like structure that has basic operations like\n// getNext(), peek(), hasNext()\n// Best practice to call peek() and then getNext()\nimport Tokens from \"./Tokens\";\n\nexport default class Tokenizer {\n    private program: string\n    private tokens: string[]\n    private currentIdx: number\n    private lineNumber: number\n\n    constructor(programString: string) {\n        this.program = programString\n        this.tokens = []\n        this.currentIdx = 0\n        this.lineNumber = 1\n        this.tokenize()\n    }\n\n    private tokenize(): void {\n        this.program = this.program.charAt(0) + \" \" + this.program.substring(1) // Add a space between @ and name for header\n        \n        // add space between literal for tokenizing\n        for(let literal of Tokens.literals){\n            let regex = new RegExp(this.escapeRegex(literal),'g');\n            this.program = this.program.replace(regex, ' '+literal+' ')\n        }\n        this.program = this.program.replace(/\\n+/g, '\\n')\n        let enhanced = this.program.split('\\n').join(' NEW_LINE ')\n        \n        this.tokens = enhanced.match(/\\S+/g) as string[]\n        console.log('TOKENS:', this.tokens) // fixme remove\n    }\n\n    // getNext returns the next token of the program, and advances the token list\n    public getNext(): string {\n        if (this.peek() != null) {\n            let token = this.tokens[this.currentIdx]\n            this.currentIdx++\n            if (token === Tokens.NEW_LINE) {\n                this.lineNumber++\n            }\n            return token;\n        }\n        throw new Error(\"No more tokens to consume\")\n    }\n\n    // peek returns the next token\n    public peek(): string | null {\n        if (this.currentIdx < this.tokens.length) {\n            return this.tokens[this.currentIdx]\n        }\n        return null\n    }\n\n    // returns true if there are more tokens left, else returns false\n    public hasNext(): boolean {\n        return this.peek() !== null\n    }\n\n    public getCurrentLine(): number {\n        return this.lineNumber\n    }\n\n    // returns a string after escaping regular expression characters in given string\n    private escapeRegex(str:string):string {\n        return str.replace(/[\\-\\[\\]\\/\\{\\}\\(\\)\\*\\+\\?\\.\\\\\\^\\$\\|]/g, \"\\\\$&\");\n      }\n}\n","import Tokenizer from \"../tokenizer/Tokenizer\";\n\nexport abstract class AbstractParser {\n    abstract parse(context: Tokenizer): any\n}","export default class ParserError extends Error {\n    constructor(expected: string, actual: string, lineNumber: number) {\n        super(`Expected ${expected} but got ${actual} at line: ${lineNumber}`);\n    }\n}","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport ParserError from \"./ParserError\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport {Variable} from \"../types/Variable\";\n\nexport class VarDecParser extends AbstractParser {\n    parse(context: Tokenizer): Variable {\n        if (context.peek() !== Tokens.VAR_KEYWORD) {\n            throw new ParserError(Tokens.VAR_KEYWORD, context.peek()!, context.getCurrentLine())\n        }\n        context.getNext() // consume VAR_DEC\n        const name = context.getNext()\n        let regExp = RegExp('^[A-Za-z0-9_]+$');\n        if (!regExp.test(name)) {\n            throw new ParserError(\"variable name\", name, context.getCurrentLine())\n        }\n        if (context.peek() !== Tokens.VAR_DEC_START) {\n            throw new ParserError(Tokens.VAR_DEC_START, context.peek()!, context.getCurrentLine())\n        }\n        context.getNext() // consume var start\n        let str = \"\"\n        while (context.peek() !== Tokens.VAR_DEC_END) {\n            const t = context.getNext()\n            if (t === Tokens.NEW_LINE) {\n                str += \"\\n\"\n            } else {\n                str += `${t} `\n            }\n        }\n        context.getNext() // consume VAR_DEC_END\n        return {\n            name,\n            value: str\n        }\n    }\n}","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport {Variable, VarMap} from \"../types/Variable\";\nimport {VarDecParser} from \"./VarDecParser\";\n\nexport class DataParser extends AbstractParser {\n    parse(context: Tokenizer): VarMap {\n        while (context.hasNext() && context.peek() !== Tokens.DATA_START) {\n            context.getNext()\n        }\n        if (context.hasNext()) {\n            context.getNext()// CONSUME DATA_START\n        }\n        let varMap: VarMap = new Map<string, Variable>()\n        while (context.hasNext()) {\n            while (context.peek() === Tokens.NEW_LINE) {\n                context.getNext()\n            }\n            if (context.peek() === Tokens.VAR_KEYWORD) {\n                let varDec = new VarDecParser().parse(context);\n                varMap.set(varDec.name, varDec)\n            }\n            while (context.peek() === Tokens.NEW_LINE) {\n                context.getNext()\n            }\n        }\n        return varMap\n    }\n}","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport {PlainText} from \"../types/Text\";\nimport Tokens from  \"../tokenizer/Tokens\";\n\n// Consumes all tokens upto delimiter and returns them as a space-seperated concatenated string, it does not consume the delimiter\nexport default class PlaintextParser extends AbstractParser {\n    private readonly delimiter: string\n    private readonly delimiterList = [Tokens.TOKEN_DECORATOR_START,\n        Tokens.EMPHASIS_DECORATOR_START,\n        Tokens.ICON_START,\n        Tokens.NEW_LINE]\n\n    constructor(delimiter: string) {\n        super()\n        this.delimiter = delimiter\n    }\n\n    parse(context: Tokenizer): PlainText {\n        let text = \"\"\n        switch (this.delimiter) {\n            case \"\":\n                let peek = context.peek()\n                while (peek !== null) {\n                    if (this.delimiterList.includes(peek)) {\n                        break; // do not consume the next token because it will be used\n                    }\n                    text += context.getNext() + ' '\n                    peek = context.peek()\n                }\n                break;\n\n            default:\n                while (context.peek() !== this.delimiter) {\n                    text += context.getNext() + ' '\n                }\n                break;\n\n        }\n        return {\n            value: text\n        }\n    }\n}\n","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport ParserError from \"./ParserError\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport {Header} from \"../types/Header\";\nimport PlaintextParser from \"./PlaintextParser\";\nimport {PlainText} from \"../types/Text\";\n\nexport default class HeaderParser extends AbstractParser {\n    parse(context: Tokenizer): Header {\n        // Get NAME\n        let headerStart = context.getNext()\n        if (headerStart !== Tokens.USER_NAME) {\n            throw new ParserError(Tokens.USER_NAME, headerStart, context.getCurrentLine())\n        }\n        let nameParsed = new PlaintextParser(Tokens.NEW_LINE).parse(context);\n        context.getNext() // consume NEW_LINE\n\n        // Get Links\n        let links = [] as Array<PlainText>\n        while (context.hasNext() && context.peek() !== Tokens.HEADER_BODY_DIV) {\n            links.push(this.parseLink(context))\n        }\n\n        return {\n            name: nameParsed,\n            links: links\n        }\n    }\n\n    parseLink(context: Tokenizer): PlainText {\n        let linkParsed = new PlaintextParser(Tokens.NEW_LINE).parse(context);\n        context.getNext() // consume NEW_LINE\n        return linkParsed\n    }\n\n}","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport {Text, PlainText} from \"../types/Text\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport PlaintextParser from \"./PlaintextParser\";\n\nexport class TextParser extends AbstractParser {\n    parse(context: Tokenizer): Text {\n\n        let text = {} as Text\n        let plainTextParser = {} as PlaintextParser\n        let initialText = {} as PlainText\n\n        // check next token and evaluate based on the type of the text\n        switch (context.peek()) {\n            case Tokens.EMPHASIS_DECORATOR_START:\n                // emphasis text\n                context.getNext()   // consume the emphasis start token\n                plainTextParser = new PlaintextParser(Tokens.EMPHASIS_DECORATOR_END)\n                initialText = plainTextParser.parse(context)\n                text.value = initialText.value\n                text.decorator = 'EMPHASIS'\n                context.getNext()   // consume the emphasis end token\n                break;\n            case Tokens.TOKEN_DECORATOR_START:\n                // tokened text(skill)\n                context.getNext()  // consume the token(skill) start token\n                plainTextParser = new PlaintextParser(Tokens.TOKEN_DECORATOR_END)\n                initialText = plainTextParser.parse(context)\n                text.value = initialText.value\n                text.decorator = 'TOKEN'\n                context.getNext()   // consume the token end token\n                break;\n            case Tokens.LINE_BREAK:\n                // Line break\n                context.getNext()// consume LINE_BREAK token\n                if (context.peek() === Tokens.NEW_LINE) {\n                    context.getNext() // Consume the next line and continue on\n                }\n                text.value = \"\"\n                text.decorator = \"BREAK\"\n                break\n            case Tokens.ICON_START:\n                // icon\n                context.getNext()  // consume the icon start token\n                plainTextParser = new PlaintextParser(Tokens.ICON_END)\n                initialText = plainTextParser.parse(context)\n                text.value = initialText.value\n                text.decorator = 'ICON'\n                context.getNext()   // consume the token end token\n                break;\n            default:\n                // raw text(normal string: no emphasis, no token)\n                plainTextParser = new PlaintextParser(\"\")\n                initialText = plainTextParser.parse(context)\n                text.value = initialText.value\n                text.decorator = 'RAW'\n                break;\n        }\n\n        return text\n    }\n\n}\n","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport {RichText} from \"../types/Text\";\nimport {TextParser} from \"./TextParser\";\nimport Tokens from \"../tokenizer/Tokens\";\n\nexport class RichTextParser extends AbstractParser {\n    parse(context: Tokenizer): RichText {\n        let value = [] as RichText\n        let nextToken = context.peek()\n        while (nextToken !== null) {\n            const t = new TextParser().parse(context)\n            value.push(t)\n            nextToken = context.peek()\n\n            // if NEW_LINE then we just read the whole sentence; break;\n            if (nextToken === Tokens.NEW_LINE) {\n                context.getNext()   // consume NEW_LINE\n                break\n            }\n        }\n        return value\n    }\n}","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport {SectionText} from \"../types/Text\";\nimport Tokens from \"../tokenizer/Tokens\"\nimport {RichTextParser} from \"./RichTextParser\";\n\nexport class SummaryParser extends AbstractParser {\n    parse(context: Tokenizer): SectionText {\n        let sectionText = {} as SectionText\n        // first check if its bullet pointed entry\n        let nextToken = context.peek()\n        if (nextToken === Tokens.BULLET_KEY) {\n            sectionText.is_bullet = true\n            context.getNext()   // consume the bullet token\n            nextToken = context.peek()   // point to the next token\n        } else {\n            sectionText.is_bullet = false\n        }\n        // if not null and not NEW_LINE then there is a text to parse in same line\n        sectionText.value = []\n        if (nextToken !== null) {\n            sectionText.value = new RichTextParser().parse(context)\n        }\n        return sectionText\n    }\n}\n","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport {Entry} from \"../types/Section\";\nimport {RichText, SectionText} from \"../types/Text\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport {SummaryParser} from \"./SummaryParser\";\nimport {RichTextParser} from \"./RichTextParser\";\n\nexport class EntryParser extends AbstractParser {\n    private entryEndArray = [Tokens.SECTION_TITLE_KEY, Tokens.ENTRY_SUBTITLE_KEY, Tokens.ENTRY_TITLE_KEY]\n\n    parse(context: Tokenizer): Entry {\n        let title: RichText = []\n        let subtitle: RichText = []\n\n        if (context.peek() === Tokens.ENTRY_TITLE_KEY) {\n            context.getNext()\n            title = new RichTextParser().parse(context);\n        }\n\n        if (context.peek() === Tokens.ENTRY_SUBTITLE_KEY) {\n            context.getNext()\n            subtitle = new RichTextParser().parse(context);\n        }\n\n        let summary = [] as Array<SectionText>\n        let peek = context.peek()\n\n        while (peek !== null && !(this.entryEndArray.includes(peek))) {\n            summary.push(new SummaryParser().parse(context))\n            peek = context.peek()\n        }\n\n        return {\n            title: title,\n            subtitle: subtitle,\n            summary: summary\n        }\n    }\n\n}\n","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport {Entry, Section} from \"../types/Section\";\nimport {EntryParser} from \"./EntryParser\";\nimport ParserError from \"./ParserError\";\nimport {RichTextParser} from \"./RichTextParser\";\nimport {RichText} from \"../types/Text\";\n\n\nexport default class SectionParser extends AbstractParser {\n    parse(context: Tokenizer): Section {\n        // Look for Section.ts Title\n        let sectionTitleKey = context.getNext()\n        let sectionTitle: RichText\n        if (sectionTitleKey === Tokens.SECTION_TITLE_KEY) {\n            sectionTitle = new RichTextParser().parse(context);\n        } else {\n            throw new ParserError(Tokens.SECTION_TITLE_KEY, sectionTitleKey, context.getCurrentLine())\n        }\n        // Parse Entries\n        let entries = [] as Array<Entry>\n        while (context.hasNext() && context.peek() !== Tokens.SECTION_TITLE_KEY) {\n            let entry = new EntryParser().parse(context);\n            entries.push(entry)\n        }\n\n        return {\n            title: sectionTitle,\n            entries: entries\n        }\n    }\n}\n","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport SectionParser from \"./SectionParser\";\nimport {Body} from \"../types/Body\"\nimport {Section} from \"../types/Section\";\n\nexport default class BodyParser extends AbstractParser {\n    parse(context: Tokenizer): Body {\n        let body = [] as Array<Section>\n        // let body = [] as Section[]\n        do {\n            let section = new SectionParser();\n            body.push(section.parse(context))\n        } while (context.hasNext())\n        return body\n    }\n}","import {AbstractParser} from \"./AbstractParser\";\nimport Tokenizer from \"../tokenizer/Tokenizer\";\nimport HeaderParser from \"./HeaderParser\";\nimport BodyParser from \"./BodyParser\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport ParserError from \"./ParserError\";\nimport {Program} from \"../types/Program\";\n\nexport class ProgramParser extends AbstractParser {\n    public parse(context: Tokenizer): Program {\n        let header;\n        let body;\n\n        let headerParser = new HeaderParser()\n        header = headerParser.parse(context);\n        if (context.hasNext()) {\n            let divHB = context.getNext()\n            if (divHB !== Tokens.HEADER_BODY_DIV) {\n                throw new ParserError(Tokens.HEADER_BODY_DIV, divHB, context.getCurrentLine())\n            }\n            context.getNext() // consume the NEXT_LINE token after header-body division\n\n            let bodyParser = new BodyParser()\n            body = bodyParser.parse(context)\n        }\n        return {\n            header,\n            body\n        }\n    }\n}","import Tokenizer from \"../tokenizer/Tokenizer\";\nimport {DataParser} from \"./DataParser\";\nimport {Variable} from \"../types/Variable\";\nimport Tokens from \"../tokenizer/Tokens\";\nimport {ProgramParser} from \"./ProgramParser\";\nimport {Program} from \"../types/Program\";\n\nexport class ResumeParser {\n    static parse(program: string): Program {\n        let t = new Tokenizer(program)\n        let varMap = new DataParser().parse(t);\n        let subProgram = program\n        varMap.forEach((varName: Variable) => {\n            subProgram = subProgram.replace(`$${varName.name}`, varName.value)\n        })\n        const dataStartIdx = subProgram.indexOf(Tokens.DATA_START)\n        if (dataStartIdx !== -1){\n            subProgram = subProgram.substring(0, dataStartIdx)\n        }\n        console.log(subProgram)\n        let p = new ProgramParser();\n\n        t = new Tokenizer(subProgram)\n        return p.parse(t);\n    }\n}","import React, {Component} from 'react';\nimport AppInput from './AppInput';\nimport AppOutput from './AppOutput';\nimport './App.css';\nimport './styles/resume.css';\nimport './styles/icofont.css';\nimport {ResumeParser} from './parser/ResumeParser';\n\nclass App extends Component {\n  state = {\n    inputValue: '',\n    parsedValue: null,\n    parsedError: null\n  };\n\n  runParser = () => {\n    let parsedResume = null;\n    try {\n      parsedResume = ResumeParser.parse(this.state.inputValue);\n      this.setState({\n        parsedValue: parsedResume,\n        parsedError: null\n      });\n    } catch (e) {\n      this.setState({parsedError: e});\n    }\n  };\n\n  handleInputValueChange = async (value: string) => {\n    await this.setState({inputValue: value});\n    this.runParser();\n  };\n\n  render = () => {\n    return (\n      <div id=\"home\">\n        {/* <div id=\"header\">\n          <span>Web Resume</span>\n        </div> */}\n        <div id=\"appBody\">\n          <AppInput\n            inputValue={this.state.inputValue}\n            handleInputValueChange={this.handleInputValueChange}\n          />\n          <AppOutput\n            parsed={this.state.parsedValue}\n            error={this.state.parsedError}\n          />\n        </div>\n      </div>\n    );\n  };\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.1/8 is considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\ntype Config = {\n  onSuccess?: (registration: ServiceWorkerRegistration) => void;\n  onUpdate?: (registration: ServiceWorkerRegistration) => void;\n};\n\nexport function register(config?: Config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(\n      (process as { env: { [key: string]: string } }).env.PUBLIC_URL,\n      window.location.href\n    );\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl: string, config?: Config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl: string, config?: Config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl)\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready.then(registration => {\n      registration.unregister();\n    });\n  }\n}\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport * as serviceWorker from './serviceWorker';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}